---
title: "p8105_hw6_zq2227"
author: "Zixuan Qiu zq2227"
date: "2023-12-01"
output: github_document
---

```{r message=FALSE}
library(tidyverse)
library(readr)
library(broom)
library(modelr)

set.seed(1)
```
# Problem 1
```{r}
url= "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data =read.csv(url)
str(homicide_data)
```

```{r message=FALSE}
homicide_data=homicide_data|>
  mutate(city_state = paste(city,state, sep = ", "))|>
  mutate(solved=ifelse(disposition== "Closed by arrest",1,0))
  
omit_cities = c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")

homicide_data=homicide_data|>
  filter(!city_state %in% omit_cities)|>
  filter(victim_race %in%c("White", "Black"))|>
  mutate(victim_age=as.numeric(victim_age))
```

```{r}
baltimore= homicide_data|>
  filter(city_state == "Baltimore, MD")
```

**glm baltimore**
```{r}
glmbaltimore= glm(solved ~ victim_age + victim_race + victim_sex, data = baltimore, family = binomial()) 

glmtidy=tidy(glmbaltimore)
glmtidy
```

**odds ratio for solving homicides comparing male victims to female victims**
```{r}
oddratio= glmtidy|>
  filter(term == "victim_sexMale")|>
  mutate(OR = exp(estimate),
         LowerCI = exp(estimate - 1.96 * std.error),
         UpperCI = exp(estimate + 1.96 * std.error))

oddratio
```

**glm for each of the cities**
```{r}
#creat function 
glmfunction = function(df) {
  glm_model = glm(solved ~ victim_age + victim_sex + victim_race, data = df, family = binomial())
  tidy(glm_model)
}

cityglm= homicide_data|>
  group_by(city_state)|>
  nest()|>
  mutate(model=map(data,glmfunction))|>
  select(city_state,model)|>
  unnest(model)
```
**odd ratio of each city**
```{r}
odds_ratio_city = cityglm|>
  filter(term == "victim_sexMale") |>
  mutate(OR = exp(estimate),
         LowerCI = exp(estimate - 1.96 * std.error),
         UpperCI = exp(estimate + 1.96 * std.error))|>
  select(city_state, OR, LowerCI, UpperCI)

odds_ratio_city
```
**plot:estimated ORs and CIs for each city**
```{r}
ggplot(odds_ratio_city,aes(x=reorder(city_state,OR),y=OR))+
  geom_point()+
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), width = 0.2)+
  coord_flip()+
  labs(title = "Odds Ratios by City",
       subtitle = "Male vs Female Victims",
       x = "City",
       y = "Odds Ratio (Male vs Female Victims)") +
  theme_minimal() 
```
**comment :The plot presents the odds ratios for solving homicides in various cities, comparing male to female victims, city such as  Albuquerque and Stockton  has a significant larger odds ratios greater than 1 means that  homicide cases of  male victims are more likely to be solved compared to female victims.Cities  likes New York and Baltimore has a small odds ratios below 1 indicate that  a higher solved proportion of  female victims compared to male victims. The width of the confidence intervals indicate the precise estimates of the odds ratio.**

# Problem 2 
```{r}
#download the central park data
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

**ues modelr::boostrap function to draw bootstrap samples**
```{r}
initial_model = lm(tmax ~ tmin + prcp, data = weather_df)

tidy(initial_model)
```

```{r}
bootstrap_results =weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin + prcp, data = .) ),
    results = map(models, broom::glance))|>
  unnest(results)
```
```{r}
r_squared =bootstrap_results |>
  select(.id,r.squared)


quantiles_r_squared = quantile(r_squared$r.squared, probs = c(0.025, 0.975))
quantiles_r_squared #2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2
```
**R_squared distribution plot**
```{r}
ggplot(r_squared, aes(x = r.squared)) + 
  geom_density(fill = "blue") + 
  theme_minimal() + 
  labs(title = "Density Plot of r-squared", 
       x = "r-squared", 
       y = "Density")
```
**Describe:the 2.5% quantile is approximately 0.888, and the 97.5% quantile is approximately 0.9409, the narrow CI indicate the high precision in the estimate.The plot's shape indicates that the distribution of r^2 is concentrated close to 0.91 that is  a high value, suggesting that the model has a good fit in most of the bootstrap samples, the outputs demonstrate a strong linear relationship captured by the regression model across the bootstrap samples.**


**log(tmin * prcp)**
```{r}
logresult=weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin + prcp, data = .) ),
    log_result=map(models,broom::tidy))|>
  unnest(log_result)
```

```{r}
logclean = logresult|>
  select(.id,term,estimate)|>
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  )|>
  mutate(log_product = log(tmin * prcp))|>
  na.omit()

quantiles_log = quantile(logclean$log_product, probs = c(0.025, 0.975))
quantiles_log
```
**log(tmin * prcp) distribution plot**
```{r}
ggplot(logclean, aes(x =log_product )) + 
  geom_histogram( fill = "blue", color = "black") + 
  theme_minimal() + 
  labs(title = "Distribution of log(tmin * prcp)", 
       x = "log(tmin * prcp)", 
       y = "Frequency")
```
**Describe: The 95 CI of the log(tmin * prcp)  is -8.884759 -4.603985. The distribution  of the value is left-skewed and have a long left tail. THe mean value is smaller than median. The distribution of the values does not trend to normal distribution.**



# Problem 3
```{r}
birthweight= read.csv("./Data/birthweight.csv")

birthweight=birthweight|>
  mutate(babysex=as.factor(babysex))|>
  mutate(malform=as.factor(malform))|>
  mutate(frace=as.factor(frace))|>
  mutate(mrace=as.factor(mrace))|>
  select(-pnumlbw, -pnumsga) 
```


### Assume  bwt as an outcome that may depend on wtgain( mother’s weight gain during pregnancy) and mrace(mother’s race)  , fit that initial model.
```{r}
fit1 = lm(bwt ~ wtgain+mrace , data = birthweight)

tidy(fit1)

```
```{r}
birthweight=birthweight|>
  add_predictions(fit1, var = "fitted_values")|>
  add_residuals(fit1, var = "residuals")
```
**Model Explanation： Initial Model: Influence of Mother's Weight Gain and Race In first model, we hypothesized that a baby's birth weight (bwt) could be influenced by two main factors: the mother's weight gain during pregnancy (wtgain) and the mother's race (mrace).**
```{r}
ggplot(birthweight, aes(x = fitted_values, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals")
```
**The residual vs fitted valued plot shows the most of the residual points appear to randomly surround the red dashed line y=0, and there are some outlines far from the dashed line. The  residual distribution indicate there are no clear trend or pattern between residual and pitted valued, it means that the fit of the model is reasonable overall, but may require Further improvements for the Homoscedasticity  of the residual.**

### One using length at birth and gestational age as predictors (main effects only)
```{r}
fit2 =lm(bwt ~ blength+gaweeks, data = birthweight)
tidy(fit2)

```
### One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
fit3 = lm(bwt ~ bhead * blength * babysex, data = birthweight)
tidy(fit3)
```

### crossv_mc  compare
```{r}
cv_df =
  crossv_mc(birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```
```{r}
cv_df = 
  cv_df |> 
  mutate(
    fit1  = map(train, \(df)  lm(bwt ~ wtgain+mrace , data = df)),
    fit2     = map(train, \(df) lm(bwt ~ blength+gaweeks, data = df)),
    fit3  = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse_fit1 = map2_dbl(fit1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_fit2 = map2_dbl(fit2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_fit3 = map2_dbl(fit3, test, \(mod, df) rmse(model = mod, data = df)))
```
```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()+theme_minimal() 
```
**These RMSE plot hows that Model 3, despite being the most complex, actually did the best job at predicting the baby's birth weight. The lower the RMSE, the closer our model's predictions are to the actual values, which is what we want in a good model. Model 3 has the lowest RMSE, followed by Model 2, and then Model 1.**

 